{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2bacd4-3d79-4f1b-b89e-327325a453d8",
   "metadata": {},
   "source": [
    "Person and vehicle transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "952a2d2a-7cbd-46e2-abd0-e1a79f111302",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL Server version  8.3.0\n",
      "Error while connecting to MySQL Failed executing the operation; Not enough parameters for the SQL statement\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Database connection parameters\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': 'Gouthi321@',  # Replace with your actual password\n",
    "    'database': 'crash_data'\n",
    "}\n",
    "\n",
    "# Connect to the database\n",
    "try:\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "    if connection.is_connected():\n",
    "        db_info = connection.get_server_info()\n",
    "        print(\"Connected to MySQL Server version \", db_info)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Define the file path to your CSV file\n",
    "        csv_file_path = '/Users/gouthamvemula/Downloads/Dataset/crashes.csv'  # Replace with the actual file path\n",
    "\n",
    "        # Read and insert data in chunks\n",
    "        chunksize = 15000  # Adjust chunksize as per your system's capability\n",
    "        for chunk in pd.read_csv(csv_file_path, chunksize=chunksize, dtype=str):\n",
    "            # Replace NaN with None and convert strings to floats for lat and lon\n",
    "            chunk = chunk.where(pd.notna(chunk), None)\n",
    "            chunk['LATITUDE'] = pd.to_numeric(chunk['LATITUDE'], errors='coerce')\n",
    "            chunk['LONGITUDE'] = pd.to_numeric(chunk['LONGITUDE'], errors='coerce')\n",
    "\n",
    "            # Format date columns\n",
    "            chunk['CRASH DATE'] = pd.to_datetime(chunk['CRASH DATE'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "            # Filter out invalid latitudes and longitudes\n",
    "            chunk = chunk[(chunk['LATITUDE'].between(-90, 90)) & (chunk['LONGITUDE'].between(-180, 180))]\n",
    "\n",
    "            # Prepare location data\n",
    "            chunk['LOCATION'] = chunk.apply(lambda x: f'POINT({x[\"LONGITUDE\"]} {x[\"LATITUDE\"]})' if pd.notna(x['LONGITUDE']) and pd.notna(x['LATITUDE']) else None, axis=1)\n",
    "\n",
    "            # Convert the DataFrame to a list of tuples\n",
    "            data_tuples = [tuple(x) for x in chunk.to_numpy()]\n",
    "\n",
    "            # Prepare the insert statement with ON DUPLICATE KEY UPDATE clause\n",
    "            insert_query = \"\"\"\n",
    "            INSERT INTO Crashes (\n",
    "                `CRASH DATE`, `CRASH TIME`, `BOROUGH`, `ZIP CODE`, `LATITUDE`, `LONGITUDE`,\n",
    "                `LOCATION`, `ON STREET NAME`, `CROSS STREET NAME`, `OFF STREET NAME`,\n",
    "                `NUMBER OF PERSONS INJURED`, `NUMBER OF PERSONS KILLED`,\n",
    "                `NUMBER OF PEDESTRIANS INJURED`, `NUMBER OF PEDESTRIANS KILLED`,\n",
    "                `NUMBER OF CYCLIST INJURED`, `NUMBER OF CYCLIST KILLED`,\n",
    "                `NUMBER OF MOTORIST INJURED`, `NUMBER OF MOTORIST KILLED`,\n",
    "                `CONTRIBUTING FACTOR VEHICLE 1`, `CONTRIBUTING FACTOR VEHICLE 2`,\n",
    "                `CONTRIBUTING FACTOR VEHICLE 3`, `CONTRIBUTING FACTOR VEHICLE 4`,\n",
    "                `CONTRIBUTING FACTOR VEHICLE 5`, `COLLISION_ID`,\n",
    "                `VEHICLE TYPE CODE 1`, `VEHICLE TYPE CODE 2`, `VEHICLE TYPE CODE 3`,\n",
    "                `VEHICLE TYPE CODE 4`, `VEHICLE TYPE CODE 5`\n",
    "            ) VALUES (%s, %s, %s, %s, %s, %s, ST_GeomFromText(%s, 4326), %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            ON DUPLICATE KEY UPDATE\n",
    "                `CRASH DATE` = VALUES(`CRASH DATE`),\n",
    "                `CRASH TIME` = VALUES(`CRASH TIME`),\n",
    "                `BOROUGH` = VALUES(`BOROUGH`),\n",
    "                `ZIP CODE` = VALUES(`ZIP CODE`),\n",
    "                `LATITUDE` = VALUES(`LATITUDE`),\n",
    "                `LONGITUDE` = VALUES(`LONGITUDE`),\n",
    "                `LOCATION` = VALUES(`LOCATION`),\n",
    "                `ON STREET NAME` = VALUES(`ON STREET NAME`),\n",
    "                `CROSS STREET NAME` = VALUES(`CROSS STREET NAME`),\n",
    "                `OFF STREET NAME` = VALUES(`OFF STREET NAME`),\n",
    "                `NUMBER OF PERSONS INJURED` = VALUES(`NUMBER OF PERSONS INJURED`),\n",
    "                `NUMBER OF PERSONS KILLED` = VALUES(`NUMBER OF PERSONS KILLED`),\n",
    "                `NUMBER OF PEDESTRIANS INJURED` = VALUES(`NUMBER OF PEDESTRIANS INJURED`),\n",
    "                `NUMBER OF PEDESTRIANS KILLED` = VALUES(`NUMBER OF PEDESTRIANS KILLED`),\n",
    "                `NUMBER OF CYCLIST INJURED` = VALUES(`NUMBER OF CYCLIST INJURED`),\n",
    "                `NUMBER OF CYCLIST KILLED` = VALUES(`NUMBER OF CYCLIST KILLED`),\n",
    "                `NUMBER OF MOTORIST INJURED` = VALUES(`NUMBER OF MOTORIST INJURED`),\n",
    "                `NUMBER OF MOTORIST KILLED` = VALUES(`NUMBER OF MOTORIST KILLED`),\n",
    "                `CONTRIBUTING FACTOR VEHICLE 1` = VALUES(`CONTRIBUTING FACTOR VEHICLE 1`),\n",
    "                `CONTRIBUTING FACTOR VEHICLE 2` = VALUES(`CONTRIBUTING FACTOR VEHICLE 2`),\n",
    "                `CONTRIBUTING FACTOR VEHICLE 3` = VALUES(`CONTRIBUTING FACTOR VEHICLE 3`),\n",
    "                `CONTRIBUTING FACTOR VEHICLE 4` = VALUES(`CONTRIBUTING FACTOR VEHICLE 4`),\n",
    "                `CONTRIBUTING FACTOR VEHICLE 5` = VALUES(`CONTRIBUTING FACTOR VEHICLE 5`),\n",
    "                `VEHICLE TYPE CODE 1` = VALUES(`VEHICLE TYPE CODE 1`),\n",
    "                `VEHICLE TYPE CODE 2` = VALUES(`VEHICLE TYPE CODE 2`),\n",
    "                `VEHICLE TYPE CODE 3` = VALUES(`VEHICLE TYPE CODE 3`),\n",
    "                `VEHICLE TYPE CODE 4` = VALUES(`VEHICLE TYPE CODE 4`),\n",
    "                `VEHICLE TYPE CODE 5` = VALUES(`VEHICLE TYPE CODE 5`)\n",
    "            \"\"\"\n",
    "\n",
    "            # Execute the insert query\n",
    "            cursor.executemany(insert_query, data_tuples)\n",
    "            connection.commit()\n",
    "            print(f\"Processed {cursor.rowcount} rows in the Crashes table.\")\n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)\n",
    "finally:\n",
    "    if connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bddc7237-0ebc-4262-a62b-3357b274d95d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL Server version  8.3.0\n",
      "MySQL connection is closed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2', 'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 55\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Convert the DataFrame to a list of tuples\u001b[39;00m\n\u001b[1;32m     42\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCRASH DATE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCRASH TIME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBOROUGH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZIP CODE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLATITUDE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLONGITUDE\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOCATION\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mON STREET NAME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCROSS STREET NAME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOFF STREET NAME\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVEHICLE TYPE CODE 4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVEHICLE TYPE CODE 5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     54\u001b[0m ]\n\u001b[0;32m---> 55\u001b[0m data_tuples \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(row) \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m chunk[columns]\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Prepare the insert statement with ON DUPLICATE KEY UPDATE clause\u001b[39;00m\n\u001b[1;32m     58\u001b[0m placeholders \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(columns))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2', 'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Database connection parameters\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': 'Gouthi321@',  # Replace with your actual password\n",
    "    'database': 'crash_data'\n",
    "}\n",
    "\n",
    "# Connect to the database\n",
    "try:\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "    if connection.is_connected():\n",
    "        db_info = connection.get_server_info()\n",
    "        print(\"Connected to MySQL Server version \", db_info)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Define the file path to your CSV file\n",
    "        csv_file_path = '/Users/gouthamvemula/Downloads/Dataset/crashes.csv'\n",
    "\n",
    "        # Read and insert data in chunks\n",
    "        chunksize = 15000  # Adjust chunksize as per your system's capability\n",
    "        for chunk in pd.read_csv(csv_file_path, chunksize=chunksize, dtype=str):\n",
    "            # Replace NaN with None and convert strings to floats for lat and lon\n",
    "            chunk = chunk.where(pd.notna(chunk), None)\n",
    "            chunk['LATITUDE'] = pd.to_numeric(chunk['LATITUDE'], errors='coerce')\n",
    "            chunk['LONGITUDE'] = pd.to_numeric(chunk['LONGITUDE'], errors='coerce')\n",
    "\n",
    "            # Format date columns\n",
    "            chunk['CRASH DATE'] = pd.to_datetime(chunk['CRASH DATE'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "            # Filter out invalid latitudes and longitudes\n",
    "            chunk = chunk[(chunk['LATITUDE'].between(-90, 90)) & (chunk['LONGITUDE'].between(-180, 180))]\n",
    "\n",
    "            # Prepare location data\n",
    "            chunk['LOCATION'] = chunk.apply(lambda x: f'POINT({x[\"LONGITUDE\"]} {x[\"LATITUDE\"]})' if pd.notna(x['LONGITUDE']) and pd.notna(x['LATITUDE']) else None, axis=1)\n",
    "\n",
    "            # Convert the DataFrame to a list of tuples\n",
    "            columns = [\n",
    "                'CRASH DATE', 'CRASH TIME', 'BOROUGH', 'ZIP CODE', 'LATITUDE', 'LONGITUDE',\n",
    "                'LOCATION', 'ON STREET NAME', 'CROSS STREET NAME', 'OFF STREET NAME',\n",
    "                'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED',\n",
    "                'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED',\n",
    "                'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED',\n",
    "                'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED',\n",
    "                'CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2',\n",
    "                'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4',\n",
    "                'CONTRIBUTING FACTOR VEHICLE 5', 'COLLISION_ID',\n",
    "                'VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2', 'VEHICLE TYPE CODE 3',\n",
    "                'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5'\n",
    "            ]\n",
    "            data_tuples = [tuple(row) for _, row in chunk[columns].iterrows()]\n",
    "\n",
    "            # Prepare the insert statement with ON DUPLICATE KEY UPDATE clause\n",
    "            placeholders = ', '.join(['%s'] * len(columns))\n",
    "            insert_query = f\"\"\"\n",
    "            INSERT INTO Crashes (\n",
    "                `{'`, `'.join(columns)}`\n",
    "            ) VALUES ({placeholders})\n",
    "            ON DUPLICATE KEY UPDATE\n",
    "                `{'` = VALUES(`'.join(columns)}`)\n",
    "            \"\"\"\n",
    "\n",
    "            # Execute the insert query\n",
    "            cursor.executemany(insert_query, data_tuples)\n",
    "            connection.commit()\n",
    "            print(f\"Processed {cursor.rowcount} rows in the Crashes table.\")\n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)\n",
    "finally:\n",
    "    if connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa03577e-04f2-4f94-aecc-b9f9459a8811",
   "metadata": {},
   "source": [
    "crashes table insert statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c225e71e-a6a0-4c71-8094-548869f9cd4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL Server version  8.3.0\n",
      "Error while connecting to MySQL 1054 (42S22): Unknown column 'CRASH DATE' in 'field list'\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Database connection parameters\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': 'Gouthi321@',  # Replace with your actual password\n",
    "    'database': 'crash_data'\n",
    "}\n",
    "\n",
    "# Connect to the database\n",
    "try:\n",
    "    connection = mysql.connector.connect(**db_config)\n",
    "    if connection.is_connected():\n",
    "        db_info = connection.get_server_info()\n",
    "        print(\"Connected to MySQL Server version \", db_info)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        #  file path to your CSV file\n",
    "        csv_file_path = '/Users/gouthamvemula/Downloads/Motor_Vehicle_Collisions_-_Crashes_20240425 (2).csv'  # Replace with the actual file path\n",
    "\n",
    "        # Read and insert data in chunks\n",
    "        chunksize = 15000  # Adjust chunksize as per your system's capability\n",
    "        for chunk in pd.read_csv(csv_file_path, chunksize=chunksize, dtype=str):\n",
    "            # Replace NaN with None and convert strings to floats for lat and lon\n",
    "            chunk = chunk.where(pd.notna(chunk), None)\n",
    "            chunk['LATITUDE'] = pd.to_numeric(chunk['LATITUDE'], errors='coerce')\n",
    "            chunk['LONGITUDE'] = pd.to_numeric(chunk['LONGITUDE'], errors='coerce')\n",
    "\n",
    "            # Format date columns\n",
    "            chunk['CRASH DATE'] = pd.to_datetime(chunk['CRASH DATE'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "            # Filter out invalid latitudes and longitudes\n",
    "            chunk = chunk[(chunk['LATITUDE'].between(-90, 90)) & (chunk['LONGITUDE'].between(-180, 180))]\n",
    "\n",
    "            # Prepare location data\n",
    "            chunk['LOCATION'] = chunk.apply(lambda x: f'POINT({x[\"LONGITUDE\"]} {x[\"LATITUDE\"]})' if pd.notna(x['LONGITUDE']) and pd.notna(x['LATITUDE']) else None, axis=1)\n",
    "\n",
    "            # Convert the DataFrame to a list of tuples\n",
    "            data_tuples = [tuple(x) for x in chunk.to_numpy()]\n",
    "\n",
    "            # Prepare the insert statement based on the table columns\n",
    "            insert_query = \"\"\"\n",
    "            INSERT INTO Crashes (\n",
    "                `CRASH DATE`, `CRASH TIME`, `BOROUGH`, `ZIP CODE`, `LATITUDE`, `LONGITUDE`,\n",
    "                `LOCATION`, `ON STREET NAME`, `CROSS STREET NAME`, `OFF STREET NAME`, \n",
    "                `NUMBER OF PERSONS INJURED`, `NUMBER OF PERSONS KILLED`,\n",
    "                `NUMBER OF PEDESTRIANS INJURED`, `NUMBER OF PEDESTRIANS KILLED`, \n",
    "                `NUMBER OF CYCLIST INJURED`, `NUMBER OF CYCLIST KILLED`, \n",
    "                `NUMBER OF MOTORIST INJURED`, `NUMBER OF MOTORIST KILLED`,\n",
    "                `CONTRIBUTING FACTOR VEHICLE 1`, `CONTRIBUTING FACTOR VEHICLE 2`, \n",
    "                `CONTRIBUTING FACTOR VEHICLE 3`, `CONTRIBUTING FACTOR VEHICLE 4`, \n",
    "                `CONTRIBUTING FACTOR VEHICLE 5`, `COLLISION_ID`,\n",
    "                `VEHICLE TYPE CODE 1`, `VEHICLE TYPE CODE 2`, `VEHICLE TYPE CODE 3`, \n",
    "                `VEHICLE TYPE CODE 4`, `VEHICLE TYPE CODE 5`\n",
    "            ) VALUES (%s, %s, %s, %s, %s, %s, ST_GeomFromText(%s, 4326), %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            \n",
    "            # Execute the insert query\n",
    "            cursor.executemany(insert_query, data_tuples)\n",
    "            connection.commit()\n",
    "            print(f\"Inserted {cursor.rowcount} rows into Crashes table.\")\n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)\n",
    "finally:\n",
    "    if connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c0974-0a31-4fe3-9717-191d3131f64e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
